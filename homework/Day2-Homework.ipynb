{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Homework Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise: Auto-tuning Metropolis-Hastings\n",
    "\n",
    "Modify the Metropolis-Hastings algorithm below by adding logic to automatically change the proposal scale depending on the acceptance rate of the chain, targeting an acceptance rate of around 30%. Call the new function `metropolis_tuned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "age = np.array([13, 14, 14,12, 9, 15, 10, 14, 9, 14, 13, 12, 9, 10, 15, 11, \n",
    "                15, 11, 7, 13, 13, 10, 9, 6, 11, 15, 13, 10, 9, 9, 15, 14, \n",
    "                14, 10, 14, 11, 13, 14, 10])\n",
    "price = np.array([2950, 2300, 3900, 2800, 5000, 2999, 3950, 2995, 4500, 2800, \n",
    "                  1990, 3500, 5100, 3900, 2900, 4950, 2000, 3400, 8999, 4000, \n",
    "                  2950, 3250, 3950, 4600, 4500, 1600, 3900, 4200, 6500, 3500, \n",
    "                  2999, 2600, 3250, 2500, 2400, 3990, 4600, 450,4700])/1000.\n",
    "\n",
    "rnorm = np.random.normal\n",
    "runif = np.random.rand\n",
    "\n",
    "from scipy.stats import gamma, norm\n",
    "dgamma = gamma.logpdf\n",
    "dnorm = norm.logpdf\n",
    "\n",
    "def calc_posterior(a, b, t, y=price, x=age):\n",
    "    # Calculate joint posterior, given values for a, b and t\n",
    "\n",
    "    # Priors on a,b\n",
    "    logp = dnorm(a, 0, 10000) + dnorm(b, 0, 10000)\n",
    "    # Prior on t\n",
    "    logp += dgamma(t, 0.001, 0.001)\n",
    "    # Calculate mu\n",
    "    mu = a + b*x\n",
    "    # Data likelihood\n",
    "    logp += sum(dnorm(y, mu, t**-0.5))\n",
    "    \n",
    "    return logp\n",
    "\n",
    "def metropolis(n_iterations, initial_values, prop_var=1):\n",
    "\n",
    "    n_params = len(initial_values)\n",
    "            \n",
    "    # Initial proposal standard deviations\n",
    "    prop_sd = [prop_var]*n_params\n",
    "    \n",
    "    # Initialize trace for parameters\n",
    "    trace = np.empty((n_iterations+1, n_params))\n",
    "    \n",
    "    # Set initial values\n",
    "    trace[0] = initial_values\n",
    "        \n",
    "    # Calculate joint posterior for initial values\n",
    "    current_log_prob = calc_posterior(*trace[0])\n",
    "    \n",
    "    # Initialize acceptance counts\n",
    "    accepted = [0]*n_params\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "    \n",
    "        if not i%1000: print('Iteration %i' % i)\n",
    "    \n",
    "        # Grab current parameter values\n",
    "        current_params = trace[i]\n",
    "    \n",
    "        for j in range(n_params):\n",
    "    \n",
    "            # Get current value for parameter j\n",
    "            p = trace[i].copy()\n",
    "    \n",
    "            # Propose new value\n",
    "            if j==2:\n",
    "                # Ensure tau is positive\n",
    "                theta = np.exp(rnorm(np.log(current_params[j]), prop_sd[j]))\n",
    "            else:\n",
    "                theta = rnorm(current_params[j], prop_sd[j])\n",
    "            \n",
    "            # Insert new value \n",
    "            p[j] = theta\n",
    "    \n",
    "            # Calculate log posterior with proposed value\n",
    "            proposed_log_prob = calc_posterior(*p)\n",
    "    \n",
    "            # Log-acceptance rate\n",
    "            alpha = proposed_log_prob - current_log_prob\n",
    "    \n",
    "            # Sample a uniform random variate\n",
    "            u = runif()\n",
    "    \n",
    "            # Test proposed value\n",
    "            if np.log(u) < alpha:\n",
    "                # Accept\n",
    "                trace[i+1,j] = theta\n",
    "                current_log_prob = proposed_log_prob\n",
    "                accepted[j] += 1\n",
    "            else:\n",
    "                # Reject\n",
    "                trace[i+1,j] = trace[i,j]\n",
    "                \n",
    "    return trace, accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Cancer Rate Estimation\n",
    "\n",
    "[Tsutakawa et al. (1985)](http://onlinelibrary.wiley.com/doi/10.1002/sim.4780040210/abstract) provides mortality data for stomach cancer among men aged 45-64 in several cities in Missouri. The file `cancer.csv` contains deaths $y_i$ and subjects at risk $n_i$ for 20 cities from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54</td>\n",
       "      <td>53637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y      n\n",
       "0    0   1083\n",
       "1    0    855\n",
       "2    2   3461\n",
       "3    0    657\n",
       "4    1   1208\n",
       "5    1   1025\n",
       "6    0    527\n",
       "7    2   1668\n",
       "8    1    583\n",
       "9    3    582\n",
       "10   0    917\n",
       "11   1    857\n",
       "12   1    680\n",
       "13   1    917\n",
       "14  54  53637\n",
       "15   0    874\n",
       "16   0    395\n",
       "17   1    581\n",
       "18   3    588\n",
       "19   0    383"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cancer = pd.read_csv('../data/cancer.csv')\n",
    "cancer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a simple binomial model, which assumes independent samples from a binomial distribution with probability of mortality $p$, we can use MLE to obtain an estimate of this probability.\n",
    "\n",
    "$$\\hat{p} = \\frac{y}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009933126276616582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_hat = cancer.y.sum() / cancer.n.sum()\n",
    "p_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial variance can be caclulated by:\n",
    "\n",
    "$$\\text{Var}(y) = np(1-p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.92947480343602"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mle_var = (cancer.n * p_hat * (1-p_hat)).sum()\n",
    "mle_var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we compare this to the observed variance in $y$, things don't look good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.84750000000003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.var(cancer.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are *overdispersed* relative to what would be expected from a binomial model. As you might expect, it is unrealistic to assume the prevalence of cancer to be the same in all cities. Rather, a more realistic model might allow the probability to vary from place to place, according to any number of unmeasured risk factors. \n",
    "\n",
    "Create a hierarchical model that allows the cancer prevalence to vary. \n",
    "\n",
    "*Hint: a reasonable distribution for probabilities is the beta distribution. So, you would want to estimate the hyperparameters of the beta distribution to fit the hierarchical model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Effects of coaching on SAT scores\n",
    "\n",
    "This example was taken from Gelman *et al.* (2013):\n",
    "\n",
    "> A study was performed for the Educational Testing Service to analyze the effects of special coaching programs on test scores. Separate randomized experiments were performed to estimate the effects of coaching programs for the SAT-V (Scholastic Aptitude Test- Verbal) in each of eight high schools. The outcome variable in each study was the score on a special administration of the SAT-V, a standardized multiple choice test administered by the Educational Testing Service and used to help colleges make admissions decisions; the scores can vary between 200 and 800, with mean about 500 and standard deviation about 100. The SAT examinations are designed to be resistant to short-term efforts directed specifically toward improving performance on the test; instead they are designed to reflect knowledge acquired and abilities developed over many years of education. Nevertheless, each of the eight schools in this study considered its short-term coaching program to be successful at increasing SAT scores. Also, there was no prior reason to believe that any of the eight programs was more effective than any other or that some were more similar in effect to each other than to any other.\n",
    "\n",
    "You are given the estimated coaching effects (`d`) and their sampling variances (`s`). The estimates were obtained by independent experiments, with relatively large sample sizes (over thirty students in each school), so you can assume that they have approximately normal sampling distributions with known variances variances.\n",
    "\n",
    "Here are the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 8\n",
    "d = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.])\n",
    "s = np.array([15., 10., 16., 11.,  9., 11., 10., 18.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct an appropriate model for estimating whether coaching effects are positive, using a **centered parameterization**, and then compare the diagnostics for this model to that from an **uncentered parameterization**.\n",
    "\n",
    "Finally, perform goodness-of-fit diagnostics on the better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('bayes_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "485c2aecfeff35fe97c500045cb91db26354005e32990317d3834cb0213a269e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
