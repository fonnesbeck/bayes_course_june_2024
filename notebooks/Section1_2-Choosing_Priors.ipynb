{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fonnesbeck/bayes_course_june_2024/blob/master/notebooks/Section1_2-Choosing_Priors.ipynb)\n",
    "\n",
    "# Choosing Prior Distributions and Likeihood Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It may already be apparent to you that specifying a Bayesian model (or any statistical model, as it happens) requires making a number of **subjective choices**. In particular, we need to specify the prior distributions for our parameters. A prior is a distribution that represents our beliefs about the parameters before we have seen the data.\n",
    "\n",
    "This notebook will guide through that process. We'll learn:\n",
    "- Some common priors for common use-cases\n",
    "- How to choose priors visually\n",
    "- How to choose priors computationally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There has been much debate in the statistical community over the years about Bayesian priors. In the end though, most of the fuss is unwarranted: priors are just **hypotheses** (or more correctly, components of a hypothesis -- your model), and hypotheses can be tested and refined.\n",
    "\n",
    "This already answers the main question we hear from beginners: \"*what's the best prior?*\". Remember that there are bad priors, but there is no best, ideal prior. You're never tied to a single prior, you can always change it if warranted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Principles vs. Techniques\n",
    "\n",
    "This is part of the \"art\" of Bayesian statistical modeling: you get to be creative, because with explicit control over the components of your model you can explore different hypotheses. This requires learning **principles** instead of **techniques**. Once you understand those core principles, you can always combine them to creatively answer your questions. Whereas, if you focus on techniques, you're lost the day you don't have the technique that exactly fits your problem.\n",
    "\n",
    "However, learning those principles can be intimidating and overwhelming at first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Choosing a Likelihood Function\n",
    "\n",
    "In the debate over prior choice, the likelihood function is often overlooked. The likelihood function is the workhorse of the model, as it determines how the information from the data are incorporated into the model for inference. \n",
    "\n",
    "$$\\Large Pr(y | \\theta)$$\n",
    "\n",
    "The likelihood function returns the probability of data values given the parameters. It can also be used as a sampling distribution for the data in a simulation context. \n",
    "\n",
    "Ultimately, the likelihood function describes how observed data are distributed, conditional on the modeled parameters. Thus, the criteria for choosing a likelihood are related to what the data look like:\n",
    "\n",
    "- **data type**: Is the target variable a continuous variable, such as height, distance, time, or a z-score? Or is it a discrete variable, such as a count, a binary variable, or a categorical variable?\n",
    "- **variable support**: Can the variable take any real value, or is it restricted to a certain range, such as positive values, or values between 0 and 1?\n",
    "- **shape**: Are the data approximately symmetric? Do they have extreme values? Are they multimodal? Are they truncated or censored?\n",
    "\n",
    "A decision tree for selecting a likelihood can be helpful. This is by no means exhaustive and you should not feel yourself constrained to these choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![image](images/likelihood.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing Prior Distributions\n",
    "\n",
    "While choosing prior distributions may superficially seem similar to choosing likelihood functions, it is a fundamentally different task. The goal with prior specification is to encode whatever information is available regarding the unknown parameter in question, outside of what is provided by the data. While the likelihood function is meant to describe **aleatoric uncertainty**, the prior distribution is meant to describe **epistemic uncertainty**.\n",
    "\n",
    "Aleatoric uncertainty is **inherent stochasticity** in the system itself. It's the kind of uncertainty you can't reduce no matter how much information (*i.e.* data) you have. Think about the probability of observing a particular card drawn from a deck of cards -- despite complete knowledge of the underlying system, the card drawn from a shuffled deck will always be random. \n",
    "\n",
    "Epistemic uncertainty, on the other hand, is due to a lack of **knowledge**, and that uncertainty can be reduced by gathering more information. For instance, you might be unsure about the weather tomorrow. But by checking the forecast, you can reduce your epistemic uncertainty.\n",
    "\n",
    "When the sample size of your training dataset is large, the posterior distribution will converge to a normal distribution regardless of the prior distribution, as long as the prior is a proper distribution (integrates to 1). This is known as the Bernstein-von Mises theorem (or, **Bayesian central limit theorem**). As a result, for large sample sizes, the choice of prior distribution becomes less critical since the data will dominate and the posterior will approximate a normal distribution.\n",
    "\n",
    "Theoretical considerations aside, the mechanics of choosing a prior distribution is not unlike those for choosing a likelihood function. The same considerations apply:\n",
    "\n",
    "- **data type**: In practice, latent variables tend to be continuous (at least more so than data), so continuous priors are more common. However, discrete priors can be useful in some cases. This will have implications on the method for fitting the model, as we will see.\n",
    "- **variable support**: We are often trying to infer parameters like latent means, variances, or regression coefficients. In the case of variances, we know they are positive, so we should choose a prior that respects this constraint. In the case of regression coefficients, we may have prior information that suggests some coefficients are more likely to be positive or negative.\n",
    "- **constraints**: Sometimes sets of parameters are related, and therefore constrained. For example, they may sum to zero, sum to one, or be ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![image](images/priors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Given the diversity of available statistical distributions available to be used as priors, the task of choosing priors seems daunting. However, keep in mind:\n",
    "\n",
    "- in practice, a much smaller subset of distributions are sufficient for considering in most cases; you rarely see Gumbel distributions, or Von Mises distributions, or Kroneker normal distributions used in the wild.\n",
    "- models are often robust to the choice of prior, depending on how much data you have. The data will dominate the likelihood function, and the posterior will converge to a normal distribution for large sample sizes, regardless of the prior distribution.\n",
    "- you can always change your prior if it is not working well. Often the choice of prior comes down to better performance and stability of the fitting algorithm, rather than considerations of prior information. \n",
    "\n",
    "Prior distributions should be considered a subjective component of the model structure (just like everything else in the model!). As such, they are subject to model criticism and revision. A model is just a detailed hypothesis, and hypotheses can be tested and refined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Conversion Rate estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Consider and AB testing conversion rate problem: typically, we are trying to estimate a latent conversion rate, which is a proportion. An obvious candidate for characterizing the distribution of probabilities is the **beta distribution**, as we saw in the previous section. \n",
    "\n",
    "$$\\Large\n",
    "p \\sim \\operatorname{Beta}(\\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Large E[p] = \\frac{\\alpha}{\\alpha + \\beta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Large \\text{Var}[p] = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\n",
    "$$\n",
    "\n",
    "Recall that beta distributions are parametrized by two positive real-valued **shape parameters**, $\\alpha$ and $\\beta$; these have a very direct interpretation when used as a prior distribution, that is, the number of events and non-events that your prior information represents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Alternative Parameterizations\n",
    "\n",
    "It is sometimes hard to reason directly using the concept of *prior observed data* when trying to parameterize a prior.\n",
    "\n",
    "Luckily, other parameterizations exist:\n",
    "\n",
    "- mean and sample size\n",
    "- mode and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a concrete example, let's suppose we want to express that we have no information *a priori* regarding the conversion rate, apart from the natural constraint that it lies within $[0, 1]$. \n",
    "\n",
    "#### Standard parameterization\n",
    "\n",
    "The standard parameterization, using the two shape parameters $\\alpha$ and $\\beta$, lends itself to a convenient interpretation in terms of *pseudo datapoints* observed.\n",
    "\n",
    "Specifically we can treat the *beliefs* represented by the parameters $\\alpha$ and $\\beta$  as our state of knowledge about the **conversion rate** after having observed $\\alpha - 1$ conversions and $\\beta -1$ non-conversions previously. \n",
    "\n",
    "Thus for $\\alpha = 1$ and $\\beta = 1$ we imply that all rates are equally likely. The $\\operatorname{Beta}(1,1)$ distribution is in fact the $\\operatorname{Uniform}[0,1]$ distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "a, b = 1, 1  # we observed a - 1, failures and b - 1 successes (no prior data!)\n",
    "rate_prior = pm.Beta.dist(alpha=a, beta=b)\n",
    "ax = az.plot_dist(pm.draw(rate_prior, draws=10_000))\n",
    "ax.set_title(f\"Random draws from $Beta(\\\\alpha={a}, \\\\beta={b})$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean and sample size parameterization\n",
    "\n",
    "Alternately, we can think of having no prior information about a probability as having a mean of 0.5 (*i.e.* equal probability of event or no event) and a sample size of 0. \n",
    "\n",
    "The sample size is defined here as:\n",
    "\n",
    "$$ n = \\alpha + \\beta - 2 $$\n",
    "\n",
    "as a parameter $\\kappa$, called the **concentration** defined as,\n",
    "\n",
    "$$ \\kappa = n + 2 = \\alpha + \\beta $$\n",
    "\n",
    "\n",
    "Note that given our choices,\n",
    "\n",
    "$$\\alpha = p * \\kappa = 0.5 * 2 = 1$$ \n",
    "\n",
    "and,\n",
    "\n",
    "$$\\beta = (1-p) * \\kappa = 0.5 * 2 = 1$$\n",
    "\n",
    "here, just as before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Mean and standard deviation parameterization\n",
    "\n",
    "\n",
    "Another way parameterize the $\\operatorname{Beta}$ distribution, is to focus on the **mean** and **standard deviation** of the distribution. We can derive this parameterization by solving a few [coupled equations](https://en.wikipedia.org/wiki/Beta_distribution), but PyMC makes it even easier.\n",
    "\n",
    "We can directly use the `mu` and `sigma` arguments with `pm.Beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pbar, std = 0.5, 0.288\n",
    "rate_prior = pm.Beta.dist(mu=pbar, sigma=std)\n",
    "ax = az.plot_dist(pm.draw(rate_prior, draws=10_000))\n",
    "ax.set_title(f\"Random draws from $\\\\operatorname{{Beta}}(\\\\mu={pbar}, \\\\sigma={std})$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Bonus Question:\n",
    "\n",
    "> How did we get to a standard deviation of 0.288 here?\n",
    "\n",
    "Simulation is a helpful visual approach for understanding the implications of different prior choices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Advertising Conversion Rate\n",
    "\n",
    "You work for a travel agency, GlobiTrav! \n",
    "\n",
    "A big customer asked you to place advertisements for a new holiday destination on Cape Cod in an off-shore underwater hotel. From June to October travellers will be guaranteed shark sightings from their hotel room if they stay longer than 3 days.\n",
    "\n",
    "You are supposed to place some advertisements on relevant travel meta-pages and estimate the subsequent conversion rate. The customer has several variations of their advertisement, and wants to pick the most suitable via a small pilot experiment.\n",
    "\n",
    "For each variant you will only get a few datapoints, so prior specification will matter to avoid overfitting and misinterpretation. Can you come up with and motivate a reasonable prior for the conversion rates in this case?\n",
    "\n",
    "HINT: A quick web search reveals some general information about conversion rates in the travel industry.\n",
    "\n",
    "> In the travel industry, conversion rates can vary from 0.2% to 4%. If your rate is above 2%, your website is in the top 20% of travel sites. Achieving a rate between 3% to 4% would position you among the best 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your anwser here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Informative and Uninformative Priors\n",
    "\n",
    "Formally, we justify a non-informative prior by the **Principle of Insufficient Reason**, which states that without specific reasons to favor any one outcome, it's rational to treat all outcomes as equally likely. This principle helps in assigning a fair and unbiased initial probability distribution in situations where there's a complete lack of knowledge about the likelihood of different events. However, sometimes it is inappropriate to employ an uninformative prior as we have done above. \n",
    "\n",
    "For some distributions there is no clear choice of such a prior, particularly when parameters are transformed. For example, a flat prior on the real line is not flat on the unit interval. \n",
    "\n",
    "Take a normal distribution with a large variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_normal = pm.Normal.dist(mu=0, sigma=10)\n",
    "ax = az.plot_dist(pm.draw(wide_normal, draws=10_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and transform it to the unit interval with the inverse-logit function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_logit_normal = pm.math.invlogit(wide_normal)\n",
    "ax = az.plot_dist(pm.draw(inverse_logit_normal, draws=10_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Jeffreys Prior \n",
    ">\n",
    "> The Jeffreys prior is a non-informative prior distribution for a parameter space, named after Sir Harold Jeffreys. Its density function is proportional to the square root of the determinant of the Fisher information matrix:\n",
    "> \n",
    "> $$p(\\vec{\\theta}) \\propto \\sqrt{\\det \\mathcal{I}(\\vec{\\theta})}$$\n",
    ">\n",
    "> Where $\\mathcal{I}(\\vec{\\theta})$ is the Fisher information matrix. The key feature of the Jeffreys prior is that it is invariant under transformation for the parameter vector $\\vec{\\theta}$, meaning the relative probability assigned to a volume of the probability space remains the same regardless of the parameterization used. This makes it particularly useful for scale parameters.\n",
    "> \n",
    "> For example, for a Gaussian distribution with mean $\\mu$ and fixed variance $\\sigma^2$, the Jeffreys prior for $\\mu$ is the improper uniform distribution, $p(\\mu) \\propto 1$, as it does not depend on $\\mu$. For a binomial distribution with parameter $\\theta$, the Jeffreys prior is $p(\\theta) \\propto \\theta^{-1/2}(1-\\theta)^{-1/2}$, which is a Beta(1/2, 1/2) distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stepping back from informative vs uninformative, there are two alternative interpretations of the prior distribution.\n",
    "\n",
    "1. **Population prior**: a distribution that represents a notional population of values for the parameter, from which those in the current experiment/study have been drawn.\n",
    "2. **Knowledge prior**: a distribution that represents our uncertainty about the true value of the parameter.\n",
    "\n",
    "Whether or not there are pre-existing studies or datasets that can inform the choice of prior, the choice of prior distribution should be justified in terms of the model and the problem at hand. Even without extensive domain expertise, it is usually possible to place reasonable constraints on the prior distributions of any model.\n",
    "\n",
    "For example:\n",
    "\n",
    "- if we are modeling **disease prevalence**, we know that the true value will be much closer to zero than to one.\n",
    "- in a **marketing study**, the mean cost of customer acquisition will not be tens of thousands of dollars.\n",
    "- modeling **player value/ability in sports**, we know that the distribution of player abilities is likely to be right-skewed, with few players far above the mean.\n",
    "\n",
    "When datasets are large, you can get away with gross prior misspecification. But when datasets are small, a well-specified prior can stabilize posterior estimates and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: IQ scores\n",
    "\n",
    "Consider the observatino of a 180 score in an IQ dataset, which is a normalized metric with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "<center><img src=\"https://media.giphy.com/media/3o6Zt11R527fgtrIJO/giphy.gif\" style=\"margin:auto\" height=\"400\" width=\"400\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Do we have a genius on our hands?**\n",
    "\n",
    "We know there is *measurement noise*, so we should already be skeptical.\n",
    "\n",
    "Let's build a simple model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as iq_model:\n",
    "\n",
    "    # Prior\n",
    "    iq = pm.Normal(\"iq\", 100, 100)  # totally ignorant prior assumption about IQ\n",
    "\n",
    "    eps = 30  # we assume we know our measurement error\n",
    "\n",
    "    # Likelihood\n",
    "    obs = pm.Normal(\"obs\", iq, eps, observed=180)\n",
    "\n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, ref_val=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It's very clear our model gets swayed by any data you throw at it, even with a big measurement error and only one observation! As a modeler, you don't want that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Are you sure you're that smart?**\n",
    "\n",
    "A quick internet search will inform us that IQ was constructed so as to have a mean of 100 and a standard deviation of 15, so we're even more skeptical now: an IQ of 180 is very unlikely, and we should incporporate that knowledge into our model.\n",
    "\n",
    "How? With our prior! We'll use a  $\\operatorname{Normal}(100,15)$\n",
    "  as our prior for individual IQ, which will make the model more skeptical of extreme observations -- i.e, it will need more convincing data to make extreme inferences. That's another version of the colloquial \"extraordinary claims require extraordinary evidence\". Logical, right? In Bayesian parlance, we say that the actual estimate of IQ will get regularized towards 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting more informative prior\n",
    "\n",
    "Now what happens with our informative prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as m:\n",
    "    \n",
    "    # Prior\n",
    "    iq = pm.Normal(\"iq\", 100, 15)  # weakly-informative prior\n",
    "\n",
    "    eps = 30 \n",
    "    obs = pm.Normal(\"obs\", iq, eps, observed=180)\n",
    "\n",
    "    # Sample\n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, ref_val=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "That looks more sensible, right? Our model needs more data to say that this person has an extremly high IQ. It's more probable (88%) that the person has a higher than average IQ, but not with the magnitude suggested by the data. There is even still a chance (12%) that the subject is below average. Remember: with big measurement error and only one data point, there is still a lot of uncertainty.\n",
    "\n",
    "To sum up, **informative priors are helpful because they regularize your inferences**.\n",
    "\n",
    "But remember this was just an example, setting the *measurement noise* to $30$ was an *assumption* that was not based on any particular information. A quick survey of the literature reveals that a standard deviation for measurement error of around $7$ may be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing priors computationally\n",
    "\n",
    "While you can use simulation to construct priors that meet our requirements, it does take some trial and error.\n",
    "\n",
    "Recent versions of PyMC have a convenient utility function that can specify priors with particular coverage properties, using optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASS = 0.95  # probability mass we want in an interval\n",
    "LOWER = 0.1  # lower bound of the interval\n",
    "UPPER = 3  # upper bound of the interval\n",
    "\n",
    "constrained_priors = pm.find_constrained_prior(\n",
    "    pm.Gamma, lower=LOWER, upper=UPPER, mass=MASS, init_guess=dict(alpha=1, beta=1)\n",
    ")\n",
    "\n",
    "constrained_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is particularly useful for distributions like the Gamma and Beta distributions, for which it can be difficult to develop an intuition regarding parameterization. So, if the only prior information you've got is \"**I need a Gamma that has 95% probability mass between 0.1 and 3.0**\", an approach like this is helpful.\n",
    "\n",
    "Just to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the prior distribution based on our optimized parameters\n",
    "opt_distribution = pm.Gamma.dist(**constrained_priors)\n",
    "\n",
    "# compute the mass inside our desired interval [LOWER, UPPER]\n",
    "mass_in_interval = (\n",
    "    pm.math.exp(pm.logcdf(opt_distribution, UPPER))\n",
    "    - pm.math.exp(pm.logcdf(opt_distribution, LOWER))\n",
    ").eval()\n",
    "\n",
    "print(np.abs(mass_in_interval - MASS) <= 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ax = az.plot_dist(pm.Gamma.dist(**constrained_priors, size=10_000).eval())\n",
    "ax.set_title(\n",
    "    f\"Random draws from $Gamma({round(constrained_priors['alpha'], 1)}, {round(constrained_priors['beta'], 1)})$\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated Priors\n",
    "\n",
    "In some cases, we may have prior information that suggests that the parameter of interest lies within a certain range with certainty. If you want to make use of arbitrary distributions for constructing priors, while guaranteeing that the parameter lies within a certain range, you can use a truncated distribution.\n",
    "\n",
    "The `Truncated` object can be used to wrap any distribution in PyMC and have an upper and/or lower bound specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_tmp = (180 + 155) / 2\n",
    "sigma_tmp = 10\n",
    "LOWER_trunc = 155\n",
    "UPPER_trunc = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model():\n",
    "    # specify a basic normal distribution\n",
    "    normal_heights = pm.Normal.dist(mu=mu_tmp, sigma=sigma_tmp)\n",
    "    # truncated it\n",
    "    heights_prior = pm.Truncated(\n",
    "        \"trunc_normal_prior\", normal_heights, lower=LOWER_trunc, upper=UPPER_trunc\n",
    "    )\n",
    "    # sample\n",
    "    prior_samples = pm.draw(heights_prior, draws=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_dist(prior_samples)\n",
    "ax.set_title(\n",
    "    f\"Random draws from Truncated-$Normal({round(mu_tmp, 1)}, {round(sigma_tmp, 1)})$\"\n",
    ")\n",
    "ax.axvline(x=LOWER_trunc, linestyle=\"-.\", color=\"r\")\n",
    "ax.axvline(x=UPPER_trunc, linestyle=\"-.\", color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to combine the ideas in this section. Let's say we want a Normal prior which has $95\\%$ mass between $160\\text{cm}$ and $170\\text{cm}$ and and at the same time is constrained to strictly lie between $150\\text{cm}$ and $180\\text{cm}$.\n",
    "\n",
    "How would we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you care deeply about your prior specification (you shouldn't), keep in mind that you may lose some precision on the `mass=0.95` constraint.\n",
    "\n",
    "In this particular example, the error will be very small because the bulk of the distribution sits within the truncation constraints, but this will not always be the case.\n",
    "\n",
    "However, as a *general rule of thumb*:\n",
    "\n",
    "The business of specifying prior is however usually **strict** in constraints such as the truncations, on the other hand **less strict** in the mass constraints that give us the initial parameters of our $\\operatorname{Normal}$ prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior specification tools\n",
    "\n",
    "If that is not enough to meet your prior elicitation needs, there are specialized software packages to further assist you in the process.\n",
    "\n",
    "[PreliZ](https://github.com/arviz-devs/preliz) is a Python package aimed at helping practitioners choose prior distributions by offering a set of tools for the various facets of prior elicitation. It covers a range of methods, from unidimensional prior elicitation on the parameter space to predictive elicitation on the observed space.\n",
    "\n",
    "(From the makers of ArviZ!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much do priors actually matter?\n",
    "\n",
    "In this section we are going to run a simple experiment to illustrate the impact of priors on inference.\n",
    "\n",
    "We will draw samples from the $\\operatorname{Normal}(\\mu = 150, \\sigma = 10)$ distribution and formulate two alternative models to perform inference on the mean of the distribution.\n",
    "\n",
    "1. `model_negbias` which has a $\\operatorname{Normal}(100, 10)$ prior on $\\mu$ (*i.e.* $5$ standard deviations from the mean of this prior)\n",
    "2. `model_poslowvar` which has a $\\operatorname{Normal}(200, 4)$ prior on $\\mu$ (*i.e.* $12.5$ standard deviations from the mean of this prior in the opposite direction)\n",
    "\n",
    "We then fit the models using datasets of increasing size: (`[1, 10, 100 , 250]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some normal data\n",
    "normal_data = np.random.normal(loc=150, scale=10, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_dict_negbias = {}\n",
    "sample_sizes = [1, 10, 100, 250]\n",
    "\n",
    "with pm.Model() as model_negbias:\n",
    "    # Data\n",
    "    data_obs = pm.MutableData(\"data_obs\", normal_data[:10])\n",
    "    # Prior\n",
    "    iq = pm.Normal(\"iq\", 100, 10)  # prior is biased towards lower mean than real data\n",
    "    eps = 10  # we assume we know our measurement error\n",
    "    # Likelihood\n",
    "    obs = pm.Normal(\"obs\", iq, eps, observed=data_obs)\n",
    "\n",
    "for i in sample_sizes:\n",
    "    print(f\"Running for {i} data points\")\n",
    "    with model_negbias:\n",
    "        model_negbias.set_data(\"data_obs\", normal_data[:i])\n",
    "        posterior_dict_negbias[i] = pm.sample(chains=1, progressbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_dict_poslowvar = {}\n",
    "\n",
    "with pm.Model() as model_poslowvar:\n",
    "    data_obs = pm.MutableData(\"data_obs\", normal_data[:10])\n",
    "    # Prior\n",
    "    iq = pm.Normal(\n",
    "        \"iq\", 200, 4\n",
    "    )  # prior is biased towards higher mean and we are a priori more certain about it\n",
    "    eps = 10  # we assume we know our measurement error\n",
    "    # Likelihood\n",
    "    obs = pm.Normal(\"obs\", iq, eps, observed=data_obs)\n",
    "\n",
    "for i in sample_sizes:\n",
    "    print(f\"Running for {i} data points\")\n",
    "    with model_poslowvar:\n",
    "        model_poslowvar.set_data(\"data_obs\", normal_data[:i])\n",
    "        posterior_dict_poslowvar[i] = pm.sample(chains=1, progressbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotting the posteriors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for i in sample_sizes:\n",
    "    ax.hist(\n",
    "        posterior_dict_negbias[i][\"posterior\"].data_vars[\"iq\"].values.reshape(-1),\n",
    "        histtype=\"step\",\n",
    "        label=f\"{i} data points - neg\",\n",
    "        alpha=(i + 100) / (np.max(sample_sizes) + 100),\n",
    "        density=True,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    ax.hist(\n",
    "        posterior_dict_poslowvar[i][\"posterior\"].data_vars[\"iq\"].values.reshape(-1),\n",
    "        histtype=\"step\",\n",
    "        label=f\"{i} data points - pos\",\n",
    "        alpha=(i + 100) / (np.max(sample_sizes) + 100),\n",
    "        density=True,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    ax.legend()\n",
    "ax.vlines(150, 0, 0.8, linestyle=\":\", color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the posteriors are slowly converging towards the same distribution, despite strongly contrasting priors. \n",
    "\n",
    "At $250$ data points our posteriors are already very similar, even though a priori we considered our synthetic dataset much less likely under `model_poslowvar`, as well as expecting data on oppositve sides of the true mean for our tested models!\n",
    "\n",
    "Note keep in mind that this is a fairly extreme example. You will usually select from priors that are **much less different** from each other, hence your posterior inferences would be **much more similar** even when informed by smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "iqvia_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "rise": {
   "auto_select": "none",
   "enable_chalkboard": true,
   "scroll": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
