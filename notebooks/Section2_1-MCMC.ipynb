{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fonnesbeck/bayes_course_dec_2023/blob/master/notebooks/Section1_2-Bayesian_Computation.ipynb)\n",
    "\n",
    "# Bayesian Computation\n",
    "\n",
    "Lets take a look at [Bayes formula](https://en.wikipedia.org/wiki/Bayes%27_theorem):\n",
    "\n",
    "$$P(\\theta|x) = \\frac{P(x|\\theta) P(\\theta)}{P(x)}$$\n",
    "\n",
    "We have $P(\\theta|x)$, the probability of our model parameters $\\theta$ given the data $x$ and thus our quantity of interest. To compute this we multiply the prior $P(\\theta)$ (what we think about $\\theta$ before we have seen any data) and the likelihood $P(x|\\theta)$, i.e. how we think our data is distributed. This nominator is pretty easy to solve for.\n",
    "\n",
    "However, lets take a closer look at the denominator. $P(x)$ which is also called the evidence (i.e. the evidence that the data x was generated by this model). We can compute this quantity by integrating over all possible parameter values:\n",
    "$$P(x) = \\int_\\Theta P(x, \\theta) \\, \\mathrm{d}\\theta$$\n",
    "\n",
    "This is the key difficulty with Bayes formula -- while the formula looks innocent enough, for even slightly non-trivial models you just can't compute the posterior in a closed-form way. \n",
    "\n",
    "Bayesian analysis often requires integration over multiple dimensions that is intractable both via analytic methods or standard methods of numerical integration.\n",
    "However, it is often possible to compute these integrals by simulating\n",
    "(drawing samples) from posterior distributions. For example, consider the expected value of a random variable $\\mathbf{x}$:\n",
    "\n",
    "$$E[\\mathbf{x}] = \\int \\mathbf{x} f(\\mathbf{x}) d\\mathbf{x}, \\qquad\\mathbf{x} = x_1, \\ldots ,x_k$$\n",
    "\n",
    "where $k$ (the dimension of vector $x$) is perhaps very large. If we can produce a reasonable number of random vectors $\\{{\\bf x_i}\\}$, we can use these values to approximate the unknown integral. This process is known as *Monte Carlo integration*. In general, MC integration allows integrals against probability density functions:\n",
    "\n",
    "$$I = \\int h(\\mathbf{x}) f(\\mathbf{x}) \\mathbf{dx}$$\n",
    "\n",
    "to be estimated by finite sums:\n",
    "\n",
    "$$\\hat{I} = \\frac{1}{n}\\sum_{i=1}^n h(\\mathbf{x}_i),$$\n",
    "\n",
    "where $\\mathbf{x}_i$ is a sample from $f$. This estimate is valid and useful because:\n",
    "\n",
    "-   By the strong law of large numbers:\n",
    "\n",
    "$$\\hat{I} \\rightarrow I   \\text{   with probability 1}$$\n",
    "\n",
    "-   Simulation error can be measured and controlled:\n",
    "\n",
    "$$Var(\\hat{I}) = \\frac{1}{n(n-1)}\\sum_{i=1}^n (h(\\mathbf{x}_i)-\\hat{I})^2$$\n",
    "\n",
    "And let's assume we could somehow generate samples from this unnormalized distribution. In that case we could approximate the full posterior quite easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import takewhile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse CDF sampling\n",
    "\n",
    "Given a probability density function, $p(x)$, the cumulative density function is given by \n",
    "\n",
    "$$\n",
    "\\operatorname{cdf}(x) = \\int_0^x p(t)~dt\n",
    "$$\n",
    "\n",
    "Note that the value $\\operatorname{cdf}(x)$ is \"the probability that a value is less than $x$\", and is between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rv = st.norm(0, 1)\n",
    "\n",
    "t = np.linspace(-4, 4, 300)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(t, rv.pdf(t))\n",
    "axes[0].set_title('Normal probability density function')\n",
    "axes[1].plot(t, rv.cdf(t))\n",
    "axes[1].set_title('Normal cumulative density function')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can *invert* the cumulative density function, we have a function $\\operatorname{cdf}^{-1}(t)$, where $0 \\leq t \\leq 1$. We can use this function to draw random values:\n",
    "\n",
    "1. Draw $u \\sim U(0, 1)$\n",
    "2. Use $y = \\operatorname{cdf}^{-1}(u)$ as your sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "rv = st.norm(0, 1)\n",
    "\n",
    "t = np.linspace(-4, 4, 300)\n",
    "u = np.random.rand()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "ax.plot(t, rv.cdf(t), color='C0')\n",
    "ax.text(t.min() + 0.1, u + 0.02, '$u$', fontdict={\"fontsize\": 24})\n",
    "ax.hlines(u, t.min(), rv.ppf(u), linestyles='dashed', color='C0')\n",
    "ax.vlines(rv.ppf(u), u, 0, linestyles='dashed', color='C0')\n",
    "bg_color = ax.get_facecolor()\n",
    "ax.plot(rv.ppf(u), u, 'o', mfc=bg_color, ms=15)\n",
    "ax.text(rv.ppf(u) + 0.1, 0.02, 'y', fontdict={\"fontsize\": 24})\n",
    "ax.set_xlim(t.min(), t.max())\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Inverse CDF sampling');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Inverse CDF sampling\n",
    "\n",
    "Complete the following function that implements inverse CDF sampling for the normal distribution. There is a cell below to visually check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.norm, st.gamma.ppf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(draws, inv_cdf):\n",
    "    \"\"\"Draw samples using the inverse CDF of a distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    draws : int\n",
    "        Number of draws to return\n",
    "    inv_cdf : function\n",
    "        Gives the percentile of the distribution the argument falls in.\"\"\"\n",
    "    # output should be an array of size (draws,), distributed according to inv_cdf\n",
    "    u = np.random.random(draws)\n",
    "    return inv_cdf(u)\n",
    "\n",
    "inv_cdf_normal = st.norm.ppf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Should look normally distributed!\n",
    "ax.hist(sample(10_000, inv_cdf_normal), bins='auto', density=True)\n",
    "x = np.linspace(-3, 3, 500)\n",
    "ax.plot(x, st.norm.pdf(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Inverse CDF sampling for exponential distribution (calculus required)\n",
    "\n",
    "The probability density function of the exponential distribution is \n",
    "\n",
    "$$\n",
    "p(x | \\lambda) = \\lambda e^{-\\lambda x}\n",
    "$$\n",
    "\n",
    "Calculate the cumulative density function, invert it, and use the `sample` function above to sample from the exponential function.\n",
    "\n",
    "Again, there is a plot below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_cdf_exponential(u, lam=1): \n",
    "    # Should return an array of shape `u.shape`\n",
    "    return -np.log(1 - u) / lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5), sharex=True, sharey=True)\n",
    "draws = 10_000\n",
    "\n",
    "# Two histograms should look the same\n",
    "axes[0].hist(st.expon(scale=1.).rvs(draws), bins='auto', density=True)\n",
    "axes[1].hist(sample(draws, inv_cdf_exponential), bins='auto', density=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints for previous exercise\n",
    "\n",
    "The cumulative density function is\n",
    "\n",
    "$$\n",
    "\\operatorname{cdf}(x) = 1-e^{-\\lambda x}.\n",
    "$$\n",
    "\n",
    "Invert the cumulative density function by solving \n",
    "$$\n",
    "y = 1-e^{-\\lambda x}\n",
    "$$ \n",
    "\n",
    "for $x$ in terms of $y$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "\n",
    "Most integrals are hard or impossible to do. Also, if we are iterating on a statistical model, we may want a method that works without requiring rederiving a formula for generating samples. Further, in Bayesian data analysis, we may not know a *normalizing constant*: we may only know \n",
    "\n",
    "$$\n",
    "\\tilde{p}(x) = \\frac{1}{Z_p}p(x),\n",
    "$$\n",
    "\n",
    "for some constant $Z_p$ (\"constant\" here is with respect to $x$). In order to sample, first we\n",
    "\n",
    "1. Choose a proposal distribution $q$ that you know how to sample from\n",
    "2. Choose a number $k$, so that $kq(x) \\geq \\tilde{p}(x)$ for all $x$\n",
    "\n",
    "Then, we repeatedly \n",
    "\n",
    "1. Draw a $z$ from $q$\n",
    "2. Draw a $u$ from $\\operatorname{Uniform}(0, kq(z))$\n",
    "3. If $u \\leq p(x)$, accept the draw, otherwise, reject.\n",
    "\n",
    "Importantly, every \"rejection\" is wasted computation! We will explore methods for having less wasted computation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixture_of_gaussians():\n",
    "    rvs = (st.norm(-3, 1), st.norm(0, 1), st.norm(3, 1))\n",
    "    probs = (0.5, 0.2, 0.3)\n",
    "    def pdf(x):\n",
    "        return sum(p * rv.pdf(x) for p, rv in zip(probs, rvs))\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "pdf = mixture_of_gaussians()\n",
    "q = st.norm(0, 3)\n",
    "z = q.rvs()\n",
    "u = np.random.rand() * q.pdf(z)\n",
    "k = 3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "t = np.linspace(-10, 10, 500)\n",
    "ax.plot(t, pdf(t), '-', label='$p(x)$')\n",
    "ax.fill_between(t, 0, pdf(t), alpha=0.2)\n",
    "ax.plot(t, k * q.pdf(t), '-', label='$k \\cdot \\mathcal{N}(z | 0, 3)$')\n",
    "ax.fill_between(t, pdf(t), k * q.pdf(t), alpha=0.2)\n",
    "\n",
    "bg_color = ax.get_facecolor()\n",
    "ax.vlines(z, 0, pdf(z), linestyles='dashed', color='green')\n",
    "ax.vlines(z, pdf(z), k * q.pdf(z), linestyles='dashed', color='red')\n",
    "\n",
    "# ax.plot(z, 0, 'o', label='z', ms=15, mfc=bg_color)\n",
    "ax.plot(z, pdf(z), 'o', color='C0', ms=15, mfc=bg_color)\n",
    "ax.plot(z, u, 'rx', label='$u \\sim U(0, k\\cdot\\mathcal{N}(z | 0, 3))$', ms=15, mfc=bg_color)\n",
    "ax.plot(z, k * q.pdf(z), 'o', color='C1', ms=15, mfc=bg_color)\n",
    "\n",
    "# ax.plot(z * np.ones(4), np.array([0, pdf(z), u, k * q.pdf(z)]), 'ko', ms=15, mfc=bg_color)\n",
    "\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_xlim(t.min(), t.max())\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection Sampling Example\n",
    "\n",
    "Sample from the pdf returned by `mixture_of_gaussians` using rejection sampling. We will implement this as a Python generator, and yield the proposed draw, `z`, as well as whether it was accepted. You should assume `proposal_dist` comes from `scipy.stats`, so it has a `.rvs()` method that samples, and a `.pdf` method that evaluates the probability density function at a point.\n",
    "\n",
    "If $kq(x)$ is not larger than $\\tilde{p}(x)$, throw an exception!\n",
    "\n",
    "The cell below has a plot to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejection sampler code here\n",
    "def rejection_sampler(pdf, proposal_dist, k):\n",
    "    while True:\n",
    "        z = proposal_dist.rvs()\n",
    "        q_dist = proposal_dist.pdf(z)\n",
    "        u = k * np.random.rand() * q_dist\n",
    "        assert k * q_dist >= pdf(z)\n",
    "        if u <= pdf(z):\n",
    "            accept = True\n",
    "        else:\n",
    "            accept = False\n",
    "        yield z, accept\n",
    "\n",
    "def gen_samples(draws, sampler):\n",
    "    samples = []\n",
    "    for n_draws, (z, accept) in enumerate(sampler, start=1):\n",
    "        if accept:\n",
    "            samples.append(z)\n",
    "            if len(samples) == draws:\n",
    "                return np.array(samples), n_draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mixture_of_gaussians()\n",
    "proposal_dist = st.norm(0, 3)\n",
    "k = 4\n",
    "N = 10_000\n",
    "\n",
    "samples, draws = gen_samples(N, rejection_sampler(pdf, proposal_dist, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "t = np.linspace(samples.min(), samples.max(), 500)\n",
    "\n",
    "# This histogram should look very similar to the pdf that is plotted\n",
    "ax.hist(samples, bins='auto', density=True)\n",
    "ax.plot(t, pdf(t))\n",
    "\n",
    "ax.set_title(f'{samples.size:,d} draws from the pdf with {100 * samples.size / draws:.2f}% efficiency');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: How does a rejection sampler scale with dimension?\n",
    "\n",
    "Use as your \"unknown distribution\" a multivariate Gaussian with identity covariance matrix, and use as your proposal distribution a multivariate Gaussian with covariance matrix `1.1 * I`. \n",
    "\n",
    "- Around what percent of samples are accepted with dimension 1? \n",
    "- 10 dimensions? \n",
    "- 100 dimensions? \n",
    "- What happens if you try to use 1,000 dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_sampler(attempts, sampler):\n",
    "    samples = []\n",
    "    for n_draws, (z, accept) in takewhile(lambda j: j[0] < attempts, enumerate(sampler)):\n",
    "        if accept:\n",
    "            samples.append(z)\n",
    "    return np.array(samples)        \n",
    "\n",
    "dim = 1000\n",
    "\n",
    "pdf = st.multivariate_normal(np.zeros(dim), np.eye(dim)).pdf\n",
    "proposal_dist = st.multivariate_normal(np.zeros(dim), 1.1 * np.eye(dim))\n",
    "k = pdf(0) / proposal_dist.pdf(0)\n",
    "\n",
    "sampler = rejection_sampler(pdf, proposal_dist, k)\n",
    "\n",
    "samples = finite_sampler(1_000, sampler)\n",
    "\n",
    "len(samples) / 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to MCMC\n",
    "\n",
    "One way to intuitively waste less computation is to use knowledge from your current sample to inform your next proposal: this is called a *Markov chain*. \n",
    "\n",
    "\n",
    "> ## Markov Chains\n",
    ">\n",
    "> A Markov chain is a special type of *stochastic process*. The standard definition of a stochastic process is an ordered collection of random variables:\n",
    ">\n",
    "> $$\\{X_t: t \\in T\\}$$\n",
    "> \n",
    "> where $t$ is frequently (but not necessarily) a time index. If we think of $X_t$ as a state $X$ at time $t$, and invoke the following dependence condition on each state:\n",
    "> \n",
    "> $$Pr(X_{t+1}=x_{t+1} | X_t=x_t, X_{t-1}=x_{t-1},\\ldots,X_0=x_0) = Pr(X_{t+1}=x_{t+1} | X_t=x_t)$$\n",
    "> \n",
    "> then the stochastic process is known as a Markov chain. This conditioning specifies that the future depends on the current state, but not past states.\n",
    "\n",
    "\n",
    "\n",
    "Let $t$ be the index of our current sample, $x_t$ be our current sample, and $\\operatorname{pdf}(x_t)$ be our probability density function evaluated at the current sample. We will define a *transition probability* that is conditioned on our current position: $T(x_{t + 1} | x_t)$. It turns out that a Markov chain will sample from $\\operatorname{pdf}$ if:\n",
    "\n",
    "- $T$ is ergodic (sort of techinical -- roughly $T$ is aperiodic and can explore the whole space)\n",
    "- The chain satisfies *detailed balance*, which means $\\operatorname{pdf}(x_t)T(x_{t+1} | x_t) = \\operatorname{pdf}(x_{t + 1})T(x_{t} | x_{t + 1})$.\n",
    "\n",
    "This second criteria inspires the *Metropolis acceptance criteria*: If we use any proposal with density function $\\operatorname{prop}$, we use this criterion to \"correct\" the transition probability to satisfy detailed balance:\n",
    "\n",
    "$$\n",
    "A(x_{t + 1} | x_t) = \\min\\left\\{1, \\frac{\\operatorname{pdf}(x_{t + 1})}{\\operatorname{pdf}(x_{t})}\\frac{\\operatorname{prop}(x_{t} | x_{t + 1})}{\\operatorname{prop}(x_{t + 1} | x_t)} \\right\\}\n",
    "$$\n",
    "\n",
    "Now the *Metropolis-Hastings Algorithm* is\n",
    "\n",
    "Initialize at some point $x_0$. For each iteration:\n",
    "\n",
    "1. Draw $\\tilde{x}_{t + 1} \\sim \\operatorname{prop}(x_t)$\n",
    "2. Draw $u \\sim \\operatorname{Uniform}(0, 1)$\n",
    "3. If $u < A(\\tilde{x}_{t + 1} | x_t)$, then $x_{t + 1} = \\tilde{x}_{t + 1}$. Otherwise, $x_{t + 1} = x_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(pdf, prop_dist, init=0):\n",
    "    \"\"\"Yields a sample, and whether it was accepted. Notice that,\n",
    "    unlike the rejection sampler, even when the second argument is `False`,\n",
    "    we use the sample! \n",
    "    \"\"\"\n",
    "    current = init\n",
    "    while True:\n",
    "        prop = prop_dist.rvs()\n",
    "        p_accept = min(1, pdf(prop) / pdf(current) * prop_dist.pdf(current) / prop_dist.pdf(prop))\n",
    "        accept = np.random.rand() < p_accept\n",
    "        if accept:\n",
    "            current = prop\n",
    "        yield current, accept\n",
    "        \n",
    "def gen_samples(draws, sampler):\n",
    "    \"\"\"An example of using the metropolis_hastings API.\"\"\"\n",
    "    samples = np.empty(draws)\n",
    "    accepts = 0\n",
    "    for idx, (z, accept) in takewhile(lambda j: j[0] < draws, enumerate(sampler)):\n",
    "        accepts += int(accept)\n",
    "        samples[idx] = z\n",
    "    return samples, accepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is \"tested\" in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mixture_of_gaussians()\n",
    "proposal_dist = st.norm(0, 10)\n",
    "\n",
    "samples, accepts = gen_samples(10_000, metropolis_hastings(pdf, proposal_dist))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "t = np.linspace(samples.min(), samples.max(), 500)\n",
    "ax.hist(samples, bins='auto', density=True)\n",
    "ax.plot(t, pdf(t))\n",
    "\n",
    "ax.set_title(f'{samples.size:,d} draws from the pdf with {100 * accepts / samples.size :.2f}% accept rate');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Random Walk Metropolis-Hastings\n",
    "\n",
    "This implementation is wildly inefficient! We will speed it up by fixing the proposal distribution as a Gaussian centered at the previous point (this is fairly standard). Specifically,\n",
    "$$x_{t+1} \\sim \\mathcal{N}( x_t, \\sigma),$$\n",
    "so\n",
    "$$\\operatorname{prop}(x_{t+1} | x_{t}) = \\mathcal{N}(x_{t + 1} | x_t, \\sigma)$$\n",
    "\n",
    "We call $\\sigma$ the *step size*.\n",
    "\n",
    "1. The Metropolis-Hastings acceptance criteria simplifies quite a bit - work out what $A(x_{t + 1} | x_t)$ is now.\n",
    "2. scipy.stats is doing a lot of work: `st.norm().rvs()` is ~1000x slower than `np.random.randn()`. Rewrite `metropolis_hastings` with the acceptance criteria, and without using `st.norm().rvs()` to provide proposals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rw_metropolis_hastings(pdf, proposal_sd, init=0):\n",
    "    current = init\n",
    "    while True:\n",
    "        prop = current + np.random.randn() * proposal_sd\n",
    "        # prop = st.norm(current, proposal_sd).rvs()\n",
    "        p_accept = min(1, pdf(prop) / pdf(current))\n",
    "        accept = np.random.rand() < p_accept\n",
    "        if accept:\n",
    "            current = prop\n",
    "        \n",
    "        yield current, accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mixture_of_gaussians()\n",
    "\n",
    "samples, accepts = gen_samples(40_000, rw_metropolis_hastings(pdf, 0.25))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "t = np.linspace(samples.min(), samples.max(), 500)\n",
    "ax.hist(samples, bins='auto', density=True)\n",
    "ax.plot(t, pdf(t))\n",
    "\n",
    "ax.set_title(f'{samples.size:,d} draws from the pdf with {100 * accepts / samples.size :.2f}% accept rate')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC Exercises 2\n",
    "\n",
    "1. Find a step size so that the acceptance rate is ~25%\n",
    "2. Find a step size so that the acceptance rate is ~95%\n",
    "3. What is the general relationship between step size and acceptance rate?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus exercise\n",
    "\n",
    "Write a routine for finding a step size that gives a specific acceptance rate for Metropolis-Hastings. It may be helpful to return the acceptance probability instead of (or in addition to) the `accept` boolean. Literature suggests the overly specific 23.4% acceptance rate as a good target. PyMC aims for anything between 20% and 50%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling\n",
    "\n",
    "If you can sample from all the marginal distributions, you can implement a sampler pretty efficiently just using those.\n",
    "\n",
    "Here is a stereotypical Gibbs sampling algorithm:\n",
    "\n",
    "1.  Choose starting values for states (parameters):\n",
    "    ${\\bf \\theta} = [\\theta_1^{(0)},\\theta_2^{(0)},\\ldots,\\theta_k^{(0)}]$\n",
    "\n",
    "2.  Initialize counter $j=1$\n",
    "\n",
    "3.  Draw the following values from each of the $k$ conditional\n",
    "    distributions:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\theta_1^{(j)} &\\sim& \\pi(\\theta_1 | \\theta_2^{(j-1)},\\theta_3^{(j-1)},\\ldots,\\theta_{k-1}^{(j-1)},\\theta_k^{(j-1)}) \\\\\n",
    "\\theta_2^{(j)} &\\sim& \\pi(\\theta_2 | \\theta_1^{(j)},\\theta_3^{(j-1)},\\ldots,\\theta_{k-1}^{(j-1)},\\theta_k^{(j-1)}) \\\\\n",
    "\\theta_3^{(j)} &\\sim& \\pi(\\theta_3 | \\theta_1^{(j)},\\theta_2^{(j)},\\ldots,\\theta_{k-1}^{(j-1)},\\theta_k^{(j-1)}) \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_{k-1}^{(j)} &\\sim& \\pi(\\theta_{k-1} | \\theta_1^{(j)},\\theta_2^{(j)},\\ldots,\\theta_{k-2}^{(j)},\\theta_k^{(j-1)}) \\\\\n",
    "\\theta_k^{(j)} &\\sim& \\pi(\\theta_k | \\theta_1^{(j)},\\theta_2^{(j)},\\theta_4^{(j)},\\ldots,\\theta_{k-2}^{(j)},\\theta_{k-1}^{(j)})\n",
    "\\end{aligned}$$\n",
    "\n",
    "4.  Increment $j$ and repeat until convergence occurs.\n",
    "\n",
    "This is pretty tricky to automate, since you need to know all of these conditional distributions! That said, this is often seen in science when a sampler is hand-built to do inference with a specific model. In that case, each conditional distribution might be computed by hand.\n",
    "\n",
    "### Coal mining example\n",
    "We have a time series of recorded coal mining disasters in the UK from 1851 to 1961.\n",
    "\n",
    "Occurrences of disasters in the time series is thought to be derived from a Poisson process with a large rate parameter in the early part of the time series, and from one with a smaller rate in the later part. We are interested in locating the change point in the series, which perhaps is related to changes in mining safety regulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters_array = np.array(\n",
    "    [4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3, \n",
    "     1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, \n",
    "     1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, \n",
    "     0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2, 1, 1, 1, \n",
    "     1, 2, 4, 2, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, \n",
    "     1])\n",
    "years = np.arange(1851, 1962, dtype=int)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.vlines(years, 0, disasters_array, lw=6)\n",
    "ax.set_xlim(years.min() - 1, years.max() + 1)\n",
    "ax.set_ylim(bottom=0);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing down the model and computing conditional distributions\n",
    "\n",
    "Let's step through the construction of a model for this problem, starting with the likelihood.\n",
    "It is natural to use a Poisson distribution for this type of count data. Denoting year $i$'s accident count by $y_i$, \n",
    "\n",
    "$$ y_i \\sim \\text{Poisson}(\\lambda)  $$\n",
    "\n",
    "The modeling problem revolves around estimating the values of the $\\lambda$ parameters. Looking at the time series above, it appears that the rate declines later in the time series.\n",
    "\n",
    "A ***changepoint model*** identifies a point (year) during the observation period (call it $\\tau$) after which the parameter $\\lambda$ drops to a lower value. So we are estimating two $\\lambda$ parameters: one for the early period and another for the late period.\n",
    "\n",
    "$$\n",
    "\\lambda = \n",
    "\\begin{cases}\n",
    "\\lambda_1  & \\text{if } t \\lt \\tau \\cr\n",
    "\\lambda_2 & \\text{if } t \\ge \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We need to assign prior probabilities to both $\\lambda$ parameters. The gamma distribution not only provides a continuous density function for positive numbers, but it is also **conjugate** with the Poisson sampling distribution. We will specify suitably vague hyperparameters $\\alpha$ and $\\beta$ for both priors.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\lambda_1 &\\sim \\text{Gamma}( \\alpha, \\beta ) \\cr\n",
    "\\lambda_2 &\\sim \\text{Gamma}( \\alpha, \\beta )\n",
    "\\end{aligned}$$\n",
    "\n",
    "Since we do not have any intuition about the location of the changepoint (prior to viewing the data), we will assign a discrete uniform prior over all years 1851-1962.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\tau \\sim \\text{DiscreteUniform(1851,1962) }\\cr\n",
    "& \\Rightarrow P( \\tau = k ) = \\frac{1}{111}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Now that we've specified the model (the hard part), let's implement it in PyMC (the easy part). We will use this to compare a hand-written Gibbs sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "def coal_disaster_model():\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        early_lambda = pm.Gamma('early_lambda', 1, 10)\n",
    "        late_lambda = pm.Gamma('late_lambda', 1, 10)\n",
    "        change_point = pm.DiscreteUniform('change_point', 1851, 1962)\n",
    "        \n",
    "        lam = pm.Deterministic('lam', pm.math.switch(years > change_point, late_lambda, early_lambda))\n",
    "        pm.Poisson('rate', lam, observed=disasters_array)\n",
    "\n",
    "    return model\n",
    "\n",
    "pm.model_to_graphviz(coal_disaster_model())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gibbs sampling\n",
    "\n",
    "We are interested in estimating the joint posterior of $\\lambda_1$, $\\lambda_2$ and $\\tau$ given the array of annnual disaster counts $\\mathbf{y}$. This gives:\n",
    "\n",
    "$$\n",
    " P( \\lambda_1, \\lambda_2, \\tau | \\mathbf{y} ) \\propto P(\\mathbf{y} | \\lambda_1, \\lambda_2, \\tau ) P(\\lambda_1, \\lambda_2, \\tau) \n",
    "$$\n",
    "\n",
    "To employ Gibbs sampling, we need to factor the joint posterior into the product of conditional expressions:\n",
    "\n",
    "$$\n",
    " P( \\lambda_1, \\lambda_2, \\tau | \\mathbf{y} ) \\propto P(y_{t<\\tau} | \\lambda_1, \\tau) P(y_{t\\ge \\tau} | \\lambda_2, \\tau) P(\\lambda_1) P(\\lambda_2) P(\\tau)\n",
    "$$\n",
    "\n",
    "which we have specified as:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "P( \\lambda_1, \\lambda_2, \\tau | \\mathbf{y} ) &\\propto \\left[\\prod_{t=1851}^{\\tau} \\text{Poi}(y_t|\\lambda_1) \\prod_{t=\\tau+1}^{1962} \\text{Poi}(y_t|\\lambda_2) \\right] \\text{Gamma}(\\lambda_1|\\alpha,\\beta) \\text{Gamma}(\\lambda_2|\\alpha, \\beta) \\frac{1}{111} \\\\\n",
    "&\\propto \\left[\\prod_{t=1851}^{\\tau} e^{-\\lambda_1}\\lambda_1^{y_t} \\prod_{t=\\tau+1}^{1962} e^{-\\lambda_2} \\lambda_2^{y_t} \\right] \\lambda_1^{\\alpha-1} e^{-\\beta\\lambda_1} \\lambda_2^{\\alpha-1} e^{-\\beta\\lambda_2} \\\\\n",
    "&\\propto \\lambda_1^{\\sum_{t=1851}^{\\tau} y_t +\\alpha-1} e^{-(\\beta+\\tau)\\lambda_1} \\lambda_2^{\\sum_{t=\\tau+1}^{1962} y_i + \\alpha-1} e^{-\\beta\\lambda_2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "So, the full conditionals are known, and critically for Gibbs, can easily be sampled from.\n",
    "\n",
    "$$\\lambda_1 \\sim \\text{Gamma}(\\sum_{t=1851}^{\\tau} y_t +\\alpha, \\tau+\\beta)$$\n",
    "$$\\lambda_2 \\sim \\text{Gamma}(\\sum_{t=\\tau+1}^{1962} y_i + \\alpha, 1962-\\tau+\\beta)$$\n",
    "$$\\tau \\sim \\text{Categorical}\\left( \\frac{\\lambda_1^{\\sum_{t=1851}^{\\tau} y_t +\\alpha-1} e^{-(\\beta+\\tau)\\lambda_1} \\lambda_2^{\\sum_{t=\\tau+1}^{1962} y_i + \\alpha-1} e^{-\\beta\\lambda_2}}{\\sum_{k=1851}^{1962} \\lambda_1^{\\sum_{t=1851}^{\\tau} y_t +\\alpha-1} e^{-(\\beta+\\tau)\\lambda_1} \\lambda_2^{\\sum_{t=\\tau+1}^{1962} y_i + \\alpha-1} e^{-\\beta\\lambda_2}} \\right)$$\n",
    "\n",
    "Implementing this in Python requires random number generators for both the gamma and discrete uniform distributions. We can leverage NumPy for this:\n",
    "\n",
    "So far so good! Now here's an implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sample_disaster(samples, tau=1900, early_lambda=6, late_lambda=2):\n",
    "    \"\"\"Can supply different initial conditions!\"\"\"\n",
    "    draws = np.empty((3, samples))\n",
    "    gamma_pdf = lambda lam, a, b: lam**(a-1) * np.exp(-b*lam)\n",
    "    n_years = disasters_array.shape[0]\n",
    "    years = np.arange(1851, 1962, dtype=int)\n",
    "    draws = []\n",
    "    while len(draws) < samples:\n",
    "        # update early_lambda\n",
    "        early_lambda = np.random.gamma(disasters_array[:tau - 1851].sum() + 1, 1 / (tau - 1851 + 10))\n",
    "        draws.append([early_lambda, late_lambda, tau])\n",
    "        \n",
    "        # update late_lambda\n",
    "        late_lambda = np.random.gamma(disasters_array[tau - 1851 + 1:].sum() + 1, 1 / (1962 - tau + 10))\n",
    "        draws.append([early_lambda, late_lambda, tau])\n",
    "        \n",
    "        # update tau\n",
    "        tau_probs = np.empty(n_years)\n",
    "        for t in range(n_years):\n",
    "            tau_probs[t] = (gamma_pdf(early_lambda, disasters_array[:t].sum() + 1, t + 10) *\n",
    "                            gamma_pdf(late_lambda, disasters_array[t:].sum() + 1, n_years - t + 10))\n",
    "        tau = np.random.choice(years, p=tau_probs / tau_probs.sum())\n",
    "        draws.append([early_lambda, late_lambda, tau])\n",
    "    return np.array(draws)[:samples]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our work\n",
    "\n",
    "We compare the Gibbs sampler to the PyMC model -- this one runs faster, but took longer to write!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "draws = gibbs_sample_disaster(1000)\n",
    "draws.mean(axis=0) # early_lambda, late_lambda, change_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with coal_disaster_model():\n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az.summary(trace, var_names=['early_lambda', 'late_lambda', 'change_point', ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo\n",
    "\n",
    "While flexible and easy to implement, Metropolis-Hastings (and Gibbs) sampling is a random walk\n",
    "sampler that might not be statistically efficient for many models. Specifically, for models of high dimension, random walk jumping algorithms do not perform well. It is not enough to simply guess at the next sample location; we need to make each iteration a useful draw from the posterior whenever we can, in order to have an efficient sampler for bigger models.\n",
    "\n",
    "Since Bayesian inference is all about calculating expectations over posteriors, what we seek is an algorithm that explores the area of the parameter space that contains most of the non-zero probability. This region is called the **typical set**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a Typical Set?\n",
    "\n",
    "The typical set is where most of the probability density (mass) lies in a particular volume associated with the distribution. As the dimension of a model increases, this set moves progressively further from the mode, and becomes more singular, as the result of concentration of measure.\n",
    "\n",
    "The typical set is a product of both the density, which is highest at the mode, and volume (that we integrate over), which increasingly becomes larger away from the mode as dimensionality increases. In fact, at high dimensions, the region around the mode contributes almost nothing to the expectation. We need an algorithm that will find this narrow region and explore it efficiently."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![from Hoffman and Gelman 2014](http://d.pr/i/RAA+)\n",
    "\n",
    "In this context, and when sampling from continuous variables, Hamiltonian (or Hybrid) Monte\n",
    "Carlo (HMC) can prove to be a powerful tool. It avoids\n",
    "random walk behavior by simulating a physical system governed by\n",
    "Hamiltonian dynamics, potentially avoiding tricky conditional\n",
    "distributions in the process.\n",
    "\n",
    "In HMC, model samples are obtained by simulating a physical system,\n",
    "where particles move about a high-dimensional landscape, subject to\n",
    "potential and kinetic energies. Adapting the notation from [Neal (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html),\n",
    "particles are characterized by a position vector or state\n",
    "$s \\in \\mathcal{R}^D$ and velocity vector $\\phi \\in \\mathcal{R}^D$. The\n",
    "combined state of a particle is denoted as $\\chi=(s,\\phi)$. \n",
    "\n",
    "The joint **canonical distribution** of the position and velocity can be expressed as a product of the marginal position (which is of interest) and the conditional distribution of the velocity:\n",
    "\n",
    "$$\\pi(s, \\phi) = \\pi(\\phi | s) \\pi(s)$$\n",
    "\n",
    "This joint probability can also be written in terms of an invariant **Hamiltonian function**:\n",
    "\n",
    "$$\\pi(s, \\phi) \\propto \\exp(-H(s,\\phi))$$\n",
    "\n",
    "The Hamiltonian is then defined as the sum of potential energy $E(s)$ and kinetic energy\n",
    "$K(\\phi)$, as follows:\n",
    "\n",
    "$$\\mathcal{H}(s,\\phi) = E(s) + K(\\phi)\n",
    "= E(s) + \\frac{1}{2} \\sum_i \\phi_i^2$$\n",
    "\n",
    "Instead of sampling $p(s)$ directly, HMC operates by sampling from the canonical distribution.\n",
    "\n",
    "$$p(s,\\phi) = \\frac{1}{Z} \\exp(-\\mathcal{H}(s,\\phi))=p(s)p(\\phi)$$\n",
    "\n",
    "If we choose a momentum that is independent of position, marginalizing over $\\phi$ is\n",
    "trivial and recovers the original distribution of interest.\n",
    "\n",
    "Note that the Hamiltonian $\\mathcal{H}$ is independent of the parameterization of the model, and therefore, captures the geometry of the phase space distribution, including typical set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hamiltonian Dynamics**\n",
    "\n",
    "State $s$ and velocity $\\phi$ are modified such that\n",
    "$\\mathcal{H}(s,\\phi)$ remains constant throughout the simulation. The\n",
    "differential equations are given by:\n",
    "\n",
    "$$\\begin{aligned}\\frac{ds_i}{dt} &= \\frac{\\partial \\mathcal{H}}{\\partial \\phi_i} = \\phi_i \\\\\n",
    "\\frac{d\\phi_i}{dt} &= - \\frac{\\partial \\mathcal{H}}{\\partial s_i}\n",
    "= - \\frac{\\partial E}{\\partial s_i}\n",
    "\\end{aligned}$$\n",
    "\n",
    "As shown in [Neal (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html), \n",
    "the above transformation preserves volume and is\n",
    "reversible. The above dynamics can thus be used as transition operators\n",
    "of a Markov chain and will leave $p(s,\\phi)$ invariant. That chain by\n",
    "itself is not ergodic however, since simulating the dynamics maintains a\n",
    "fixed Hamiltonian $\\mathcal{H}(s,\\phi)$. HMC thus alternates Hamiltonian\n",
    "dynamic steps, with Gibbs sampling of the velocity. Because $p(s)$ and\n",
    "$p(\\phi)$ are independent, sampling $\\phi_{new} \\sim p(\\phi|s)$ is\n",
    "trivial since $p(\\phi|s)=p(\\phi)$, where $p(\\phi)$ is often taken to be\n",
    "the univariate Gaussian.\n",
    "\n",
    "![Fisher](images/skate_park.png?raw=true)\n",
    "\n",
    "**The Leap-Frog Algorithm**\n",
    "\n",
    "In practice, we cannot simulate Hamiltonian dynamics exactly because of\n",
    "the problem of time discretization. There are several ways one can do\n",
    "this. To maintain invariance of the Markov chain however, care must be\n",
    "taken to preserve the properties of *volume conservation* and *time\n",
    "reversibility*. The **leap-frog algorithm** maintains these properties\n",
    "and operates in 3 steps:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\phi_i(t + \\epsilon/2) &= \\phi_i(t) - \\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t)) \\\\\n",
    "s_i(t + \\epsilon) &= s_i(t) + \\epsilon \\phi_i(t + \\epsilon/2) \\\\\n",
    "\\phi_i(t + \\epsilon) &= \\phi_i(t + \\epsilon/2) - \\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t + \\epsilon)) \n",
    "\\end{aligned}$$\n",
    "\n",
    "We thus perform a half-step update of the velocity at time\n",
    "$t+\\epsilon/2$, which is then used to compute $s(t + \\epsilon)$ and\n",
    "$\\phi(t + \\epsilon)$.\n",
    "\n",
    "**Accept / Reject**\n",
    "\n",
    "In practice, using finite stepsizes $\\epsilon$ will not preserve\n",
    "$\\mathcal{H}(s,\\phi)$ exactly and will introduce bias in the simulation.\n",
    "Also, rounding errors due to the use of floating point numbers means\n",
    "that the above transformation will not be perfectly reversible.\n",
    "\n",
    "HMC cancels these effects **exactly** by adding a Metropolis\n",
    "accept/reject stage, after $n$ leapfrog steps. The new state\n",
    "$\\chi' = (s',\\phi')$ is accepted with probability $p_{acc}(\\chi,\\chi')$,\n",
    "defined as:\n",
    "\n",
    "$$p_{acc}(\\chi,\\chi') = min \\left( 1, \\frac{\\exp(-\\mathcal{H}(s',\\phi')}{\\exp(-\\mathcal{H}(s,\\phi)} \\right)$$\n",
    "\n",
    "**HMC Algorithm**\n",
    "\n",
    "We obtain a new HMC sample as follows:\n",
    "\n",
    "1.  sample a new velocity from a univariate Gaussian distribution\n",
    "2.  perform $n$ leapfrog steps to obtain the new state $\\chi'$\n",
    "3.  perform accept/reject move of $\\chi'$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "Doucet, A., De Freitas, N., and Gordon, N. (2001), Sequential Monte Carlo Methods in Practice, Statistics for Engineering and Information Science, New York: Springer-Verlag.\n",
    "\n",
    "Chapter 6 of [Givens, Geof H.; Hoeting, Jennifer A. (2012-10-09). Computational Statistics (Wiley Series in Computational Statistics)](http://www.stat.colostate.edu/computationalstatistics/)\n",
    "\n",
    "Chapter 5 of [Albert, J. (2009). Bayesian computation with R.](http://www.amazon.com/Bayesian-Computation-R-Use/dp/0387922970)\n",
    "\n",
    "Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2003). Bayesian Data Analysis, Second Edition (Chapman & Hall/CRC Texts in Statistical Science) (2nd ed.). Chapman and Hall/CRC.\n",
    "\n",
    "Neal, R. M. (2003). Slice sampling. The Annals of Statistics, 31(3), 705–767. doi:10.1111/1467-9868.00198"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
